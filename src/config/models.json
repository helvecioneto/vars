{
    "providers": {
        "openai": {
            "fast": {
                "analyze": "gpt-4o-mini",
                "transcribe": "whisper-1",
                "temperature": 0.5,
                "maxOutputTokens": 1024
            },
            "balanced": {
                "analyze": "gpt-4o",
                "transcribe": "whisper-1",
                "temperature": 0.5,
                "maxOutputTokens": 4096
            },
            "quality": {
                "analyze": "gpt-5.2",
                "transcribe": "whisper-1",
                "temperature": 1,
                "maxOutputTokens": 16384,
                "topP": 1
            }
        },
        "google": {
            "free": {
                "analyze": [
                    "gemini-3-flash-preview",
                    "gemini-2.5-flash-lite",
                    "gemini-1.5-flash-8b",
                    "gemini-2.0-flash-lite"
                ],
                "transcribe": [
                    "gemini-3-flash-preview",
                    "gemini-2.5-flash-lite",
                    "gemini-1.5-flash-8b"
                ],
                "temperature": 0.5,
                "topK": 40,
                "topP": 0.95,
                "maxOutputTokens": 2048,
                "retryConfig": {
                    "maxRetries": 3,
                    "initialDelayMs": 1000,
                    "maxDelayMs": 10000,
                    "backoffMultiplier": 2,
                    "fallbackOnFailure": true
                }
            },
            "fast": {
                "analyze": "gemini-3-flash-preview",
                "transcribe": "gemini-2.0-flash",
                "temperature": 0.4,
                "topK": 40,
                "topP": 0.95,
                "maxOutputTokens": 4096
            },
            "balanced": {
                "analyze": "gemini-2.5-flash",
                "transcribe": "gemini-2.5-flash",
                "temperature": 0.3,
                "topK": 32,
                "topP": 1,
                "maxOutputTokens": 8192
            },
            "quality": {
                "analyze": "gemini-3-pro-preview",
                "transcribe": "gemini-2.5-pro",
                "temperature": 0.2,
                "topK": 20,
                "topP": 1,
                "maxOutputTokens": 8192
            }
        }
    },
    "tiers": [
        "free",
        "fast",
        "balanced",
        "quality"
    ],
    "defaultProvider": "openai",
    "defaultTier": "balanced"
}